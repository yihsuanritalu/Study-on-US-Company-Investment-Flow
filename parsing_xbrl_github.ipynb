{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import datetime as datetime\n",
    "import json\n",
    "from dateutil import relativedelta\n",
    "import webbrowser\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "#FASB US GAAP Taxonomy:https://www.fasb.org/cs/ContentServer?c=Page&cid=1176169699514&d=&pagename=FASB%2FPage%2FSectionPage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_xml_link(CIK, accession_number):\n",
    "    r = requests.get('https://www.sec.gov/Archives/edgar/data/{}/{}/index.json'.format(CIK,accession_number)).text\n",
    "    j = json.loads(r)\n",
    "    file_name = ''\n",
    "    for i in j['directory']['item']:\n",
    "        try:\n",
    "            date = i['name'].split('-')[1].split('.xml')[0]\n",
    "            datetime.datetime.strptime(date,'%Y%m%d')\n",
    "            file_name = i['name']\n",
    "            break\n",
    "        except:\n",
    "            if 'htm.xml' in i['name']:\n",
    "                file_name = i['name']\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "    \n",
    "    return 'https://www.sec.gov/Archives/edgar/data/{}/{}/{}'.format(CIK,accession_number,file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_company_document_list(company_CIK):\n",
    "    company = company_CIK\n",
    "\n",
    "    link_10Q = 'https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK={}&type=10-Q&dateb=&owner=include&count=40'.format(company)\n",
    "    link_10K = 'https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK={}&type=10-K&dateb=&owner=include&count=40'.format(company)\n",
    "    r_10Q = requests.get(link_10Q)\n",
    "    r_10K = requests.get(link_10K)\n",
    "    df_10Q = pd.read_html(r_10Q.text)[-1]\n",
    "    df_10K = pd.read_html(r_10K.text)[-1]\n",
    "    #Concat 10-K and 10-Q document list\n",
    "    df_filing = pd.concat([df_10Q,df_10K], ignore_index = True)\n",
    "    df_filing = df_filing[df_filing[0] != 'Filings']\n",
    "\n",
    "    #Extract acct_no\n",
    "    df_filing[2] = df_filing[2].apply(lambda x: x.split('Acc-no: ')[1].split('\\xa0(34 Act)')[0].replace('-',''))\n",
    "\n",
    "    df_filing[3] = df_filing[3].apply(lambda x: datetime.datetime.strptime(x,'%Y-%m-%d'))\n",
    "\n",
    "    df_filing = df_filing.loc[:,[0,2,3]]\n",
    "\n",
    "    df_filing.rename(columns = {0:'document_type',2:'Acc_no',3:'release_date'},inplace = True)\n",
    "    #order the list to get the latest filings\n",
    "    df_filing  = df_filing.sort_values(by = 'release_date',ascending = False).reset_index()\n",
    "    \n",
    "    return df_filing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reporting_period(s, df_date):\n",
    "    months = ''\n",
    "    try:\n",
    "        months = str(df_date[df_date.context == s]['months'].item()) + 'Date_Only'\n",
    "    except:\n",
    "        try:\n",
    "            for i in df_date.index:\n",
    "                element = df_date.loc[i,'context'].split('_')\n",
    "                if all(x in s for x in element):\n",
    "                    months = df_date.loc[i,'months']\n",
    "        except:\n",
    "            months = 'na'\n",
    "    return months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dateto(s, df_date):\n",
    "    dateto = ''\n",
    "    try:\n",
    "        dateto = df_date[df_date.context == s]['to'].item()\n",
    "    except:\n",
    "        try:\n",
    "            for i in df_date.index:\n",
    "                element = df_date.loc[i,'context'].split('_')\n",
    "                if all(x in s for x in element):\n",
    "                    dateto = df_date.loc[i,'to']\n",
    "        except:\n",
    "            dateto = 'na'\n",
    "    return dateto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_xbrl(xbrl_link):\n",
    "    ###############################\n",
    "#   input: xml file of the company\n",
    "#   output: the entire parsed xbrl file and taxonomy versionand company CIK\n",
    "    ###############################\n",
    "    xbrl_resp = requests.get(xbrl_link)\n",
    "    xbrl_str = xbrl_resp.text\n",
    "\n",
    "    #soup = BeautifulSoup(xbrl_str, 'lxml') --> this will truncate tag.name\n",
    "    #https://stackoverflow.com/questions/28616558/python-64-bit-not-storing-as-long-of-string-as-32-bit-python\n",
    "    soup = BeautifulSoup(xbrl_str, 'html.parser')\n",
    "    tag_list = soup.find_all()\n",
    "    df = {'us-gaap':[],'value':[],'contextref':[],'decimals':[], 'unitref':[]}\n",
    "    df_date = {'tag':[],'value':[],'context':[]}\n",
    "    df_explicitmember = {'tag':[],'name':[],'us-gaap':[]}\n",
    "    for tag in tag_list:\n",
    "        df['us-gaap'].append(tag.name)\n",
    "        df['value'].append(tag.text)\n",
    "\n",
    "        if 'contextref' in tag.attrs:\n",
    "            df['contextref'].append(tag.attrs['contextref'])\n",
    "        if 'decimals' in tag.attrs:\n",
    "            df['decimals'].append(tag.attrs['decimals'])\n",
    "        if 'unitref' in tag.attrs:\n",
    "            df['unitref'].append(tag.attrs['unitref'])\n",
    "        if 'xmlns:us-gaap' in tag.attrs:\n",
    "            xbrl_version = tag.attrs['xmlns:us-gaap'].rsplit('/',1)[1].split('-')[0]\n",
    "                \n",
    "        if 'contextref' not in tag.attrs:\n",
    "            df['contextref'].append('')\n",
    "        if 'decimals' not in tag.attrs:\n",
    "            df['decimals'].append('')\n",
    "        if 'unitref' not in tag.attrs:\n",
    "            df['unitref'].append('')\n",
    "            \n",
    "########################            \n",
    "#Get explicit member\n",
    "########################              \n",
    "        \n",
    "        if 'explicitmember' in tag.name:\n",
    "            df_explicitmember['tag'].append(tag.name)\n",
    "            df_explicitmember['name'].append(tag.text)\n",
    "            df_explicitmember['us-gaap'].append(tag.attrs['dimension'])\n",
    "            \n",
    "\n",
    "########################            \n",
    "#Get period\n",
    "########################         \n",
    "        if 'id' in tag.attrs:\n",
    "            for subtag in tag.find_all():\n",
    "                if 'period' in subtag.name:\n",
    "                    df_date['tag'].append(subtag.name)\n",
    "                    df_date['value'].append(subtag.text)\n",
    "                    df_date['context'].append(tag.attrs['id'])\n",
    "\n",
    "                    \n",
    "                    \n",
    "#########################\n",
    "#Wrangle df_explicitmember\n",
    "#########################  \n",
    "    df_explicitmember = pd.DataFrame(df_explicitmember)\n",
    "    df_explicitmember = df_explicitmember.loc[df_explicitmember['name'].str.contains('us-gaap',na = False, case = False) == False,:]\n",
    "    df_explicitmember['us-gaap'] = df_explicitmember['us-gaap'].apply(lambda x: x.lower())\n",
    "    df_explicitmember['name'] = df_explicitmember['name'].apply(lambda x: x.split(':')[1].lower())\n",
    "    df_explicitmember['label'] = df_explicitmember['name']\n",
    "    df_explicitmember['Year'] = np.repeat(xbrl_version, len(df_explicitmember.index))\n",
    "                                        \n",
    "#########################\n",
    "#Wrangle df_date\n",
    "#########################\n",
    "    df_date = pd.DataFrame(df_date)\n",
    "    df_date = df_date.loc[df_date.context.str.contains('|'.join(['us-gaap','srt','dei','axis','member']), na = False, case = False) == False,:]\n",
    "    df_date['context'] = df_date['context'].apply(lambda x: x.lower())\n",
    "    ###########Prior code\n",
    "    #df_date['from'] = df_date.value.str.extract('[\\n+]?(\\d+\\-\\d+\\-\\d+)[\\n+](\\d+\\-\\d+\\-\\d+)?')[0]\n",
    "    #df_date['to'] = df_date.value.str.extract('[\\n+]?(\\d+\\-\\d+\\-\\d+)[\\n+](\\d+\\-\\d+\\-\\d+)?')[1]\n",
    "    ###########\n",
    "    df_date['from'] = df_date.value.str.extractall('[\\n+]?(\\d+\\-\\d+\\-\\d+)[\\n+]?').unstack()[0][0]\n",
    "    df_date['to'] = df_date.value.str.extractall('[\\n+]?(\\d+\\-\\d+\\-\\d+)[\\n+]?').unstack()[0][1]\n",
    "\n",
    "########################\n",
    "#if there is only one date, then to and from should be the same\n",
    "########################\n",
    "    to = []\n",
    "    for i in df_date.index:\n",
    "        try:\n",
    "            datetime.datetime.strptime(df_date.loc[i,'to'],'%Y-%m-%d')\n",
    "            to.append(df_date.loc[i,'to'])\n",
    "        except:\n",
    "        \n",
    "            to.append(df_date.loc[i,'from'])\n",
    "    df_date['to'] = to    \n",
    "\n",
    "########################\n",
    "#calculate months between from and to date\n",
    "########################\n",
    "    months = []\n",
    "    for i in df_date.index:\n",
    "\n",
    "        f = datetime.datetime.strptime(df_date.loc[i,'from'],'%Y-%m-%d')\n",
    "        t = datetime.datetime.strptime(df_date.loc[i,'to'],'%Y-%m-%d')\n",
    "    \n",
    "        r = relativedelta.relativedelta(t, f)\n",
    "        if df_date.loc[i,'from'] == df_date.loc[i,'to']:\n",
    "            months.append(r.months)\n",
    "        elif r.years >= 1:\n",
    "            months.append(r.years*12+r.months)        \n",
    "        else:\n",
    "            months.append(r.months+1)    \n",
    "    df_date['months'] = months\n",
    "\n",
    "    df_date.sort_values(by = ['months'], ascending = False,inplace = True)\n",
    "    df_date = df_date.reset_index()\n",
    "#########################\n",
    "#Wrangle df\n",
    "#########################    \n",
    "    df = pd.DataFrame(df)\n",
    "    #CIK = df.loc[df['us-gaap'].str.contains('dei:entitycentralindexkey', case = False, na = False),'value'].item()\n",
    "    CIK = ''\n",
    "    \n",
    "    df['CIK'] = np.repeat(CIK, len(df.index))\n",
    "    df['Year'] = np.repeat(xbrl_version, len(df.index))\n",
    "    df['us-gaap'] = df['us-gaap'].apply(lambda x: x.lower())\n",
    "    df['contextref'] = df['contextref'].apply(lambda x: x.lower())\n",
    "    df['reporting_period'] = df['contextref'].apply(lambda x: reporting_period(x, df_date))\n",
    "    df['CutDate'] = df['contextref'].apply(lambda x: dateto(x, df_date))\n",
    "    \n",
    "    return df, df_explicitmember"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## us-gaap Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "taxonomy_f = ['US_GAAP_Taxonomy_2018.xlsx','US_GAAP_Taxonomy_2017.xlsx','US_GAAP_Taxonomy_2016.xlsx']\n",
    "#taxonomy_f = ['US_GAAP_Taxonomy_2018.xlsx']\n",
    "fasb = pd.DataFrame(columns = ['table_name', 'prefix', 'name', 'label', 'depth', 'order', 'priority',\n",
    "       'parent', 'arcrole', 'preferredLabel', 'systemid', 'us-gaap', 'Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in taxonomy_f:\n",
    "    year = i.rsplit('_',1)[1].split('.xlsx')[0]\n",
    "\n",
    "    us_gaap = pd.ExcelFile(i).parse('Presentation')\n",
    "    us_gaap = us_gaap.reset_index()\n",
    "\n",
    "    table_head = us_gaap.loc[us_gaap['prefix'].str.contains('definition', case = False, na = False),:].index\n",
    "    table_name = list(us_gaap.loc[table_head,'name'])\n",
    "    df_tables = pd.DataFrame(data = table_name, index = table_head, columns = ['table_name'])\n",
    "    df_tables = df_tables.reset_index()\n",
    "\n",
    "    us_gaap_with_table = df_tables.merge(us_gaap, how = 'outer', on = ['index']).sort_values(by = ['index']).set_index('index')\n",
    "    us_gaap_with_table['table_name'].fillna(method = 'ffill', inplace = True)\n",
    "\n",
    "    table_of_interest = ['104000 - Statement - Statement of Financial Position, Classified',\\\n",
    "                         '124100 - Statement - Statement of Income',\\\n",
    "                         '152200 - Statement - Statement of Cash Flows','460000 - Disclosure - Debt',\\\n",
    "                         '770000 - Disclosure - Income Taxes','300000 - Disclosure - Cash and Cash Equivalents',\\\n",
    "                         '330000 - Disclosure - Investments, Debt and Equity Securities',\\\n",
    "                         '336000 - Disclosure - Investments, All Other Investments',\\\n",
    "                         '333000 - Disclosure - Investments, Equity Method and Joint Ventures',\\\n",
    "                         '320000 - Disclosure - Receivables, Loans, Notes Receivable, and Others',\\\n",
    "                         '790000 - Disclosure - Segment Reporting',\\\n",
    "                         '800000 - Disclosure - Business Combinations',\\\n",
    "                         '815000 - Disclosure - Fair Value Measures and Disclosures',\\\n",
    "                         '993500 - Disclosure - Investment Holdings',\\\n",
    "                         '993510 - Disclosure - Other than Securities Investment Holdings',\\\n",
    "                         '993520 - Disclosure - Summary of Investment Holdings',\\\n",
    "                         '148400 - Statement - Statement of Comprehensive Income',\\\n",
    "                         '148410 - Statement - Statement of Other Comprehensive Income',\\\n",
    "                         '500000 - Disclosure - Equity']\n",
    "    us_gaap_with_table = us_gaap_with_table.loc[us_gaap_with_table['table_name'].str.contains('|'.join(table_of_interest), na = False, case = False),:]\n",
    "    us_gaap_with_table = us_gaap_with_table[us_gaap_with_table['prefix'] == 'us-gaap']\n",
    "    us_gaap_with_table['us-gaap'] = us_gaap_with_table['prefix']+':'+us_gaap_with_table['name']\n",
    "    us_gaap_with_table['us-gaap'] = us_gaap_with_table['us-gaap'].apply(lambda x: x.lower())\n",
    "    us_gaap_with_table['name'] = us_gaap_with_table['name'].apply(lambda x: x.lower())\n",
    "    us_gaap_with_table['Year'] = np.repeat(year, len(us_gaap_with_table.index))\n",
    "    \n",
    "    fasb = pd.concat([fasb,us_gaap_with_table], ignore_index = True)\n",
    "fasb = fasb[['table_name','label','depth','order','us-gaap','Year','name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############\n",
    "# This is to calculate the distance of every item to its respective member item, later for explicitmember\n",
    "#############\n",
    "distance_to_member_level = []\n",
    "result = []\n",
    "for i in fasb.index:\n",
    "    current_depth = fasb.loc[i,'depth']\n",
    "    for row in fasb.index[i+1:]:\n",
    "        \n",
    "        if fasb.loc[row,'depth'] <= fasb.loc[i,'depth']:\n",
    "            distance_to_member_level.append(current_depth-fasb.loc[i,'depth'])\n",
    "            break\n",
    "        elif 'MEMBER' in fasb.loc[row,'name'].upper():\n",
    "            if fasb.loc[row,'depth'] > current_depth:\n",
    "                current_depth = fasb.loc[row,'depth']\n",
    "        elif row == fasb.index[-1]:\n",
    "            distance_to_member_level.append(current_depth-fasb.loc[i,'depth'])\n",
    "    \n",
    "    #############\n",
    "    # For final row\n",
    "    #############\n",
    "distance_to_member_level.append(0)\n",
    "\n",
    "    \n",
    "fasb['distance_to_member_level'] = distance_to_member_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///Corp_Financials_Cash.db')\n",
    "###############\n",
    "#Access list of tables in db\n",
    "##############\n",
    "df = pd.read_sql('SELECT * FROM sp_500_tables', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############\n",
    "#import S&P 500 company list --> source: Wikipedia\n",
    "############\n",
    "#sp500 = pd.read_excel('S&P500CIK.xls')\n",
    "sp_500 = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies', header = 0)[0]\n",
    "sp_500 = sp_500.loc[sp_500['GICS Sector'].str.contains('|'.join(['Financials','Real Estate'])) == False,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame(columns = ['CIK', 'Year', 'CutDate', 'reporting_period', 'table_name', 'decimals',\\\n",
    "                                 'unitref', 'value', 'label', 'member', 'us-gaap', 'name', 'depth','contextref'])\n",
    "df_all_text = pd.DataFrame(columns = ['CIK', 'Year', 'CutDate', 'reporting_period', 'table_name', 'decimals',\\\n",
    "                                 'unitref', 'value', 'label', 'member', 'us-gaap', 'name', 'depth','contextref'])\n",
    "#CIKs = ['1513761']\n",
    "engine = create_engine('sqlite:///Corp_Financials_Cash(2).db')\n",
    "CIKs = list(set(pd.read_sql('SELECT * FROM sp_500', engine)['CIK']))\n",
    "engine = create_engine('sqlite:///Corp_Financials_Cash.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "# loop for sp_500 XBRL\n",
    "#######################\n",
    "count = 0\n",
    "failed = {'CIK':[]}\n",
    "for cik in CIKs:\n",
    "    try:\n",
    "        CIK = cik\n",
    "        Acc_no = get_company_document_list(CIK)\n",
    "        Acc_no = Acc_no[Acc_no.release_date > datetime.datetime(2018,4,1)].loc[0,'Acc_no']\n",
    "    \n",
    "        link = get_xml_link(CIK,Acc_no)\n",
    "        df_comp, df_member = parse_xbrl(link)\n",
    "        df_comp['CIK'] = np.repeat(CIK, len(df_comp.index))\n",
    "        df_comp = df_comp.merge(fasb, how = 'inner', on = ['Year','us-gaap'])\n",
    "\n",
    "#######################\n",
    "# get member item from contextref\n",
    "#######################\n",
    "        df_member = df_member.merge(fasb[['table_name','us-gaap','Year','distance_to_member_level','depth']],how = 'inner',on = ['Year','us-gaap'])\n",
    "        df_member['depth'] = df_member['depth'] + df_member['distance_to_member_level']\n",
    "\n",
    "        fasb_by_comp = fasb[fasb['Year'] == df_comp['Year'][0]]\n",
    "        fasb_with_explicitmember = pd.concat([df_member[['name', 'us-gaap', 'Year', 'table_name','depth','label']],\\\n",
    "                                              fasb_by_comp[['name', 'us-gaap', 'Year', 'table_name','depth','label']]], ignore_index = True)\n",
    "        fasb_with_explicitmember.drop_duplicates(inplace = True)\n",
    "        fasb_with_explicitmember['depth'] = fasb_with_explicitmember['depth'].astype('int')\n",
    "        member = []\n",
    "        for i in df_comp.index:\n",
    "            s = df_comp.loc[i,'contextref']\n",
    "            table = df_comp.loc[i,'table_name']\n",
    "            fasb_sort_by_table = fasb_with_explicitmember.copy()\n",
    "            fasb_sort_by_table = fasb_sort_by_table[fasb_sort_by_table['table_name'] == table]\n",
    "    \n",
    "#######################\n",
    "# First time checking if the table is empty to distinduish date only contextref, second time checking to\n",
    "# determine if the member applies to the specific table.\n",
    "#######################\n",
    "            if 'Date_Only' in str(df_comp.loc[i,'reporting_period']):\n",
    "                member.append('Date_Only')\n",
    "            else:\n",
    "                fasb_sort_by_table = fasb_sort_by_table.loc[[x in s for x in fasb_sort_by_table['name']],:]\n",
    "                fasb_sort_by_table = fasb_sort_by_table.loc[fasb_sort_by_table['name'].str.contains('axis', case = False, na = False) == False,:]\n",
    "                fasb_sort_by_table['len_name'] = fasb_sort_by_table['name'].apply(lambda x: len(x))\n",
    "                if fasb_sort_by_table.empty:\n",
    "                    member.append('')\n",
    "\n",
    "                else:\n",
    "                    fasb_sort_by_table = fasb_sort_by_table.sort_values(by = ['depth','len_name'], ascending = [False, False])\n",
    "                    member.append(fasb_sort_by_table.reset_index().loc[0,'label'])\n",
    "\n",
    "        df_comp['member'] = member\n",
    "        df_comp['reporting_period'] = df_comp['reporting_period'].apply(lambda x: int(str(x).split('Date_Only')[0]) if 'Date_Only' in str(x) else x)\n",
    "        df_comp = df_comp[df_comp['member'] != '']\n",
    "        df_comp = df_comp[['CIK','Year','CutDate','reporting_period','table_name','decimals', \\\n",
    "                           'unitref', 'value','label','member','us-gaap','name','depth','contextref']]\n",
    "        df_comp.drop_duplicates(inplace = True)\n",
    "#######################\n",
    "# Wrangle Text Block\n",
    "#######################\n",
    "        text = []\n",
    "        for i in df_comp.loc[df_comp['label'].str.contains('Text Block', na = False, case = False),'value']:\n",
    "            soup = BeautifulSoup(i,\"lxml\")\n",
    "            pageText = soup.findAll(text=True)\n",
    "            text.append(' '.join(pageText))\n",
    "        df_comp.loc[df_comp['label'].str.contains('Text Block', na = False, case = False),'value'] = text\n",
    "    \n",
    "        df_all = pd.concat([df_all,df_comp.loc[df_comp['label'].str.contains('Text Block', na = False, case = False) == False,:]], ignore_index = True)\n",
    "    \n",
    "        df_all_text = pd.concat([df_all_text,df_comp.loc[df_comp['label'].str.contains('Text Block', na = False, case = False),:]], ignore_index = True)\n",
    "        count += 1\n",
    "        print(count)\n",
    "        #time.sleep(20)\n",
    "        if count%2 == 0:\n",
    "            df_all.to_sql('sp_500_tables',engine, if_exists = 'append')\n",
    "            df_all_text.to_sql('sp_500_tables_text',engine, if_exists = 'append')\n",
    "            del(df_all)\n",
    "            del(df_all_text)\n",
    "            df_all = pd.DataFrame(columns = ['CIK', 'Year', 'CutDate', 'reporting_period', 'table_name', 'decimals',\\\n",
    "                                             'unitref', 'value', 'label', 'member', 'us-gaap', 'name', 'depth','contextref'])\n",
    "            df_all_text = pd.DataFrame(columns = ['CIK', 'Year', 'CutDate', 'reporting_period', 'table_name', 'decimals',\\\n",
    "                                                  'unitref', 'value', 'label', 'member', 'us-gaap', 'name', 'depth','contextref'])\n",
    "            \n",
    "    except:\n",
    "        failed['CIK'].append(cik)\n",
    "        #time.sleep(20)\n",
    "#############\n",
    "# To prevent lefting out the last one\n",
    "#############\n",
    "df_all.to_sql('sp_500_tables',engine, if_exists = 'append')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
