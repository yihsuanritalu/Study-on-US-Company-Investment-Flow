{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import datetime as datetime\n",
    "import json\n",
    "from dateutil import relativedelta\n",
    "import webbrowser\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "#FASB US GAAP Taxonomy:https://www.fasb.org/cs/ContentServer?c=Page&cid=1176169699514&d=&pagename=FASB%2FPage%2FSectionPage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_xml_link(CIK, accession_number):\n",
    "    r = requests.get('https://www.sec.gov/Archives/edgar/data/{}/{}/index.json'.format(CIK,accession_number)).text\n",
    "    j = json.loads(r)\n",
    "    file_name = ''\n",
    "    for i in j['directory']['item']:\n",
    "        try:\n",
    "            date = i['name'].split('-')[1].split('.xml')[0]\n",
    "            datetime.datetime.strptime(date,'%Y%m%d')\n",
    "            file_name = i['name']\n",
    "            break\n",
    "        except:\n",
    "            if 'htm.xml' in i['name']:\n",
    "                file_name = i['name']\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "    \n",
    "    return 'https://www.sec.gov/Archives/edgar/data/{}/{}/{}'.format(CIK,accession_number,file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_company_document_list(company_CIK):\n",
    "    company = company_CIK\n",
    "\n",
    "    link_10Q = 'https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK={}&type=10-Q&dateb=&owner=include&count=40'.format(company)\n",
    "    link_10K = 'https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK={}&type=10-K&dateb=&owner=include&count=40'.format(company)\n",
    "    r_10Q = requests.get(link_10Q)\n",
    "    r_10K = requests.get(link_10K)\n",
    "    df_10Q = pd.read_html(r_10Q.text)[-1]\n",
    "    df_10K = pd.read_html(r_10K.text)[-1]\n",
    "    #Concat 10-K and 10-Q document list\n",
    "    df_filing = pd.concat([df_10Q,df_10K], ignore_index = True)\n",
    "    df_filing = df_filing[df_filing[0] != 'Filings']\n",
    "\n",
    "    #Extract acct_no\n",
    "    df_filing[2] = df_filing[2].apply(lambda x: x.split('Acc-no: ')[1].split('\\xa0(34 Act)')[0].replace('-',''))\n",
    "\n",
    "    df_filing[3] = df_filing[3].apply(lambda x: datetime.datetime.strptime(x,'%Y-%m-%d'))\n",
    "\n",
    "    df_filing = df_filing.loc[:,[0,2,3]]\n",
    "\n",
    "    df_filing.rename(columns = {0:'document_type',2:'Acc_no',3:'release_date'},inplace = True)\n",
    "    #order the list to get the latest filings\n",
    "    df_filing  = df_filing.sort_values(by = 'release_date',ascending = False).reset_index()\n",
    "    \n",
    "    return df_filing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reporting_period(s, df_date):\n",
    "    months = ''\n",
    "    try:\n",
    "        months = str(df_date[df_date.context == s]['months'].item()) + 'Date_Only'\n",
    "    except:\n",
    "        try:\n",
    "            for i in df_date.index:\n",
    "                element = df_date.loc[i,'context'].split('_')\n",
    "                if all(x in s for x in element):\n",
    "                    months = df_date.loc[i,'months']\n",
    "        except:\n",
    "            months = 'na'\n",
    "    return months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dateto(s, df_date):\n",
    "    dateto = ''\n",
    "    try:\n",
    "        dateto = df_date[df_date.context == s]['to'].item()\n",
    "    except:\n",
    "        try:\n",
    "            for i in df_date.index:\n",
    "                element = df_date.loc[i,'context'].split('_')\n",
    "                if all(x in s for x in element):\n",
    "                    dateto = df_date.loc[i,'to']\n",
    "        except:\n",
    "            dateto = 'na'\n",
    "    return dateto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_xbrl(xbrl_link):\n",
    "    ###############################\n",
    "#   input: xml file of the company\n",
    "#   output: the entire parsed xbrl file and taxonomy versionand company CIK\n",
    "    ###############################\n",
    "    xbrl_resp = requests.get(xbrl_link)\n",
    "    xbrl_str = xbrl_resp.text\n",
    "\n",
    "    #soup = BeautifulSoup(xbrl_str, 'lxml') --> this will truncate tag.name\n",
    "    #https://stackoverflow.com/questions/28616558/python-64-bit-not-storing-as-long-of-string-as-32-bit-python\n",
    "    soup = BeautifulSoup(xbrl_str, 'html.parser')\n",
    "    tag_list = soup.find_all()\n",
    "    df = {'us-gaap':[],'value':[],'contextref':[],'decimals':[], 'unitref':[]}\n",
    "    df_date = {'tag':[],'value':[],'context':[]}\n",
    "    df_explicitmember = {'tag':[],'name':[],'us-gaap':[]}\n",
    "    for tag in tag_list:\n",
    "        df['us-gaap'].append(tag.name)\n",
    "        df['value'].append(tag.text)\n",
    "\n",
    "        if 'contextref' in tag.attrs:\n",
    "            df['contextref'].append(tag.attrs['contextref'])\n",
    "        if 'decimals' in tag.attrs:\n",
    "            df['decimals'].append(tag.attrs['decimals'])\n",
    "        if 'unitref' in tag.attrs:\n",
    "            df['unitref'].append(tag.attrs['unitref'])\n",
    "        if 'xmlns:us-gaap' in tag.attrs:\n",
    "            xbrl_version = tag.attrs['xmlns:us-gaap'].rsplit('/',1)[1].split('-')[0]\n",
    "                \n",
    "        if 'contextref' not in tag.attrs:\n",
    "            df['contextref'].append('')\n",
    "        if 'decimals' not in tag.attrs:\n",
    "            df['decimals'].append('')\n",
    "        if 'unitref' not in tag.attrs:\n",
    "            df['unitref'].append('')\n",
    "            \n",
    "########################            \n",
    "#Get explicit member\n",
    "########################              \n",
    "        \n",
    "        if 'explicitmember' in tag.name:\n",
    "            df_explicitmember['tag'].append(tag.name)\n",
    "            df_explicitmember['name'].append(tag.text)\n",
    "            df_explicitmember['us-gaap'].append(tag.attrs['dimension'])\n",
    "            \n",
    "\n",
    "########################            \n",
    "#Get period\n",
    "########################         \n",
    "        if 'id' in tag.attrs:\n",
    "            for subtag in tag.find_all():\n",
    "                if 'period' in subtag.name:\n",
    "                    df_date['tag'].append(subtag.name)\n",
    "                    df_date['value'].append(subtag.text)\n",
    "                    df_date['context'].append(tag.attrs['id'])\n",
    "\n",
    "                    \n",
    "                    \n",
    "#########################\n",
    "#Wrangle df_explicitmember\n",
    "#########################  \n",
    "    df_explicitmember = pd.DataFrame(df_explicitmember)\n",
    "    df_explicitmember = df_explicitmember.loc[df_explicitmember['name'].str.contains('us-gaap',na = False, case = False) == False,:]\n",
    "    df_explicitmember['us-gaap'] = df_explicitmember['us-gaap'].apply(lambda x: x.lower())\n",
    "    df_explicitmember['name'] = df_explicitmember['name'].apply(lambda x: x.split(':')[1].lower())\n",
    "    df_explicitmember['label'] = df_explicitmember['name']\n",
    "    df_explicitmember['Year'] = np.repeat(xbrl_version, len(df_explicitmember.index))\n",
    "                                        \n",
    "#########################\n",
    "#Wrangle df_date\n",
    "#########################\n",
    "    df_date = pd.DataFrame(df_date)\n",
    "    df_date = df_date.loc[df_date.context.str.contains('|'.join(['us-gaap','srt','dei','axis','member']), na = False, case = False) == False,:]\n",
    "    df_date['context'] = df_date['context'].apply(lambda x: x.lower())\n",
    "    ###########Prior code\n",
    "    #df_date['from'] = df_date.value.str.extract('[\\n+]?(\\d+\\-\\d+\\-\\d+)[\\n+](\\d+\\-\\d+\\-\\d+)?')[0]\n",
    "    #df_date['to'] = df_date.value.str.extract('[\\n+]?(\\d+\\-\\d+\\-\\d+)[\\n+](\\d+\\-\\d+\\-\\d+)?')[1]\n",
    "    ###########\n",
    "    df_date['from'] = df_date.value.str.extractall('[\\n+]?(\\d+\\-\\d+\\-\\d+)[\\n+]?').unstack()[0][0]\n",
    "    df_date['to'] = df_date.value.str.extractall('[\\n+]?(\\d+\\-\\d+\\-\\d+)[\\n+]?').unstack()[0][1]\n",
    "\n",
    "########################\n",
    "#if there is only one date, then to and from should be the same\n",
    "########################\n",
    "    to = []\n",
    "    for i in df_date.index:\n",
    "        try:\n",
    "            datetime.datetime.strptime(df_date.loc[i,'to'],'%Y-%m-%d')\n",
    "            to.append(df_date.loc[i,'to'])\n",
    "        except:\n",
    "        \n",
    "            to.append(df_date.loc[i,'from'])\n",
    "    df_date['to'] = to    \n",
    "\n",
    "########################\n",
    "#calculate months between from and to date\n",
    "########################\n",
    "    months = []\n",
    "    for i in df_date.index:\n",
    "\n",
    "        f = datetime.datetime.strptime(df_date.loc[i,'from'],'%Y-%m-%d')\n",
    "        t = datetime.datetime.strptime(df_date.loc[i,'to'],'%Y-%m-%d')\n",
    "    \n",
    "        r = relativedelta.relativedelta(t, f)\n",
    "        if df_date.loc[i,'from'] == df_date.loc[i,'to']:\n",
    "            months.append(r.months)\n",
    "        elif r.years >= 1:\n",
    "            months.append(r.years*12+r.months)        \n",
    "        else:\n",
    "            months.append(r.months+1)    \n",
    "    df_date['months'] = months\n",
    "\n",
    "    df_date.sort_values(by = ['months'], ascending = False,inplace = True)\n",
    "    df_date = df_date.reset_index()\n",
    "#########################\n",
    "#Wrangle df\n",
    "#########################    \n",
    "    df = pd.DataFrame(df)\n",
    "    #CIK = df.loc[df['us-gaap'].str.contains('dei:entitycentralindexkey', case = False, na = False),'value'].item()\n",
    "    CIK = ''\n",
    "    \n",
    "    df['CIK'] = np.repeat(CIK, len(df.index))\n",
    "    df['Year'] = np.repeat(xbrl_version, len(df.index))\n",
    "    df['us-gaap'] = df['us-gaap'].apply(lambda x: x.lower())\n",
    "    df['contextref'] = df['contextref'].apply(lambda x: x.lower())\n",
    "    df['reporting_period'] = df['contextref'].apply(lambda x: reporting_period(x, df_date))\n",
    "    df['CutDate'] = df['contextref'].apply(lambda x: dateto(x, df_date))\n",
    "    \n",
    "    return df, df_explicitmember"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## us-gaap Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "taxonomy_f = ['US_GAAP_Taxonomy_2018.xlsx','US_GAAP_Taxonomy_2017.xlsx','US_GAAP_Taxonomy_2016.xlsx']\n",
    "#taxonomy_f = ['US_GAAP_Taxonomy_2018.xlsx']\n",
    "fasb = pd.DataFrame(columns = ['table_name', 'prefix', 'name', 'label', 'depth', 'order', 'priority',\n",
    "       'parent', 'arcrole', 'preferredLabel', 'systemid', 'us-gaap', 'Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in taxonomy_f:\n",
    "    year = i.rsplit('_',1)[1].split('.xlsx')[0]\n",
    "\n",
    "    us_gaap = pd.ExcelFile(i).parse('Presentation')\n",
    "    us_gaap = us_gaap.reset_index()\n",
    "\n",
    "    table_head = us_gaap.loc[us_gaap['prefix'].str.contains('definition', case = False, na = False),:].index\n",
    "    table_name = list(us_gaap.loc[table_head,'name'])\n",
    "    df_tables = pd.DataFrame(data = table_name, index = table_head, columns = ['table_name'])\n",
    "    df_tables = df_tables.reset_index()\n",
    "\n",
    "    us_gaap_with_table = df_tables.merge(us_gaap, how = 'outer', on = ['index']).sort_values(by = ['index']).set_index('index')\n",
    "    us_gaap_with_table['table_name'].fillna(method = 'ffill', inplace = True)\n",
    "\n",
    "    table_of_interest = ['104000 - Statement - Statement of Financial Position, Classified',\\\n",
    "                         '124100 - Statement - Statement of Income',\\\n",
    "                         '152200 - Statement - Statement of Cash Flows','460000 - Disclosure - Debt',\\\n",
    "                         '770000 - Disclosure - Income Taxes','300000 - Disclosure - Cash and Cash Equivalents',\\\n",
    "                         '330000 - Disclosure - Investments, Debt and Equity Securities',\\\n",
    "                         '336000 - Disclosure - Investments, All Other Investments',\\\n",
    "                         '333000 - Disclosure - Investments, Equity Method and Joint Ventures',\\\n",
    "                         '320000 - Disclosure - Receivables, Loans, Notes Receivable, and Others',\\\n",
    "                         '790000 - Disclosure - Segment Reporting',\\\n",
    "                         '800000 - Disclosure - Business Combinations',\\\n",
    "                         '815000 - Disclosure - Fair Value Measures and Disclosures',\\\n",
    "                         '993500 - Disclosure - Investment Holdings',\\\n",
    "                         '993510 - Disclosure - Other than Securities Investment Holdings',\\\n",
    "                         '993520 - Disclosure - Summary of Investment Holdings',\\\n",
    "                         '148400 - Statement - Statement of Comprehensive Income',\\\n",
    "                         '148410 - Statement - Statement of Other Comprehensive Income',\\\n",
    "                         '500000 - Disclosure - Equity']\n",
    "    us_gaap_with_table = us_gaap_with_table.loc[us_gaap_with_table['table_name'].str.contains('|'.join(table_of_interest), na = False, case = False),:]\n",
    "    us_gaap_with_table = us_gaap_with_table[us_gaap_with_table['prefix'] == 'us-gaap']\n",
    "    us_gaap_with_table['us-gaap'] = us_gaap_with_table['prefix']+':'+us_gaap_with_table['name']\n",
    "    us_gaap_with_table['us-gaap'] = us_gaap_with_table['us-gaap'].apply(lambda x: x.lower())\n",
    "    us_gaap_with_table['name'] = us_gaap_with_table['name'].apply(lambda x: x.lower())\n",
    "    us_gaap_with_table['Year'] = np.repeat(year, len(us_gaap_with_table.index))\n",
    "    \n",
    "    fasb = pd.concat([fasb,us_gaap_with_table], ignore_index = True)\n",
    "fasb = fasb[['table_name','label','depth','order','us-gaap','Year','name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############\n",
    "# This is to calculate the distance of every item to its respective member item, later for explicitmember\n",
    "#############\n",
    "distance_to_member_level = []\n",
    "result = []\n",
    "for i in fasb.index:\n",
    "    current_depth = fasb.loc[i,'depth']\n",
    "    for row in fasb.index[i+1:]:\n",
    "        \n",
    "        if fasb.loc[row,'depth'] <= fasb.loc[i,'depth']:\n",
    "            distance_to_member_level.append(current_depth-fasb.loc[i,'depth'])\n",
    "            break\n",
    "        elif 'MEMBER' in fasb.loc[row,'name'].upper():\n",
    "            if fasb.loc[row,'depth'] > current_depth:\n",
    "                current_depth = fasb.loc[row,'depth']\n",
    "        elif row == fasb.index[-1]:\n",
    "            distance_to_member_level.append(current_depth-fasb.loc[i,'depth'])\n",
    "    \n",
    "    #############\n",
    "    # For final row\n",
    "    #############\n",
    "distance_to_member_level.append(0)\n",
    "\n",
    "    \n",
    "fasb['distance_to_member_level'] = distance_to_member_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///Corp_Financials_Cash.db')\n",
    "###############\n",
    "#Access list of tables in db\n",
    "##############\n",
    "df = pd.read_sql('SELECT * FROM sp_500_tables', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############\n",
    "#import S&P 500 company list --> source: Wikipedia\n",
    "############\n",
    "#sp500 = pd.read_excel('S&P500CIK.xls')\n",
    "sp_500 = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies', header = 0)[0]\n",
    "sp_500 = sp_500.loc[sp_500['GICS Sector'].str.contains('|'.join(['Financials','Real Estate'])) == False,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame(columns = ['CIK', 'Year', 'CutDate', 'reporting_period', 'table_name', 'decimals',\\\n",
    "                                 'unitref', 'value', 'label', 'member', 'us-gaap', 'name', 'depth','contextref'])\n",
    "df_all_text = pd.DataFrame(columns = ['CIK', 'Year', 'CutDate', 'reporting_period', 'table_name', 'decimals',\\\n",
    "                                 'unitref', 'value', 'label', 'member', 'us-gaap', 'name', 'depth','contextref'])\n",
    "#CIKs = ['1513761']\n",
    "engine = create_engine('sqlite:///Corp_Financials_Cash(2).db')\n",
    "CIKs = list(set(pd.read_sql('SELECT * FROM sp_500', engine)['CIK']))\n",
    "engine = create_engine('sqlite:///Corp_Financials_Cash.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "# loop for sp_500 XBRL\n",
    "#######################\n",
    "count = 0\n",
    "failed = {'CIK':[]}\n",
    "for cik in CIKs:\n",
    "    try:\n",
    "        CIK = cik\n",
    "        Acc_no = get_company_document_list(CIK)\n",
    "        Acc_no = Acc_no[Acc_no.release_date > datetime.datetime(2018,4,1)].loc[0,'Acc_no']\n",
    "    \n",
    "        link = get_xml_link(CIK,Acc_no)\n",
    "        df_comp, df_member = parse_xbrl(link)\n",
    "        df_comp['CIK'] = np.repeat(CIK, len(df_comp.index))\n",
    "        df_comp = df_comp.merge(fasb, how = 'inner', on = ['Year','us-gaap'])\n",
    "\n",
    "#######################\n",
    "# get member item from contextref\n",
    "#######################\n",
    "        df_member = df_member.merge(fasb[['table_name','us-gaap','Year','distance_to_member_level','depth']],how = 'inner',on = ['Year','us-gaap'])\n",
    "        df_member['depth'] = df_member['depth'] + df_member['distance_to_member_level']\n",
    "\n",
    "        fasb_by_comp = fasb[fasb['Year'] == df_comp['Year'][0]]\n",
    "        fasb_with_explicitmember = pd.concat([df_member[['name', 'us-gaap', 'Year', 'table_name','depth','label']],\\\n",
    "                                              fasb_by_comp[['name', 'us-gaap', 'Year', 'table_name','depth','label']]], ignore_index = True)\n",
    "        fasb_with_explicitmember.drop_duplicates(inplace = True)\n",
    "        fasb_with_explicitmember['depth'] = fasb_with_explicitmember['depth'].astype('int')\n",
    "        member = []\n",
    "        for i in df_comp.index:\n",
    "            s = df_comp.loc[i,'contextref']\n",
    "            table = df_comp.loc[i,'table_name']\n",
    "            fasb_sort_by_table = fasb_with_explicitmember.copy()\n",
    "            fasb_sort_by_table = fasb_sort_by_table[fasb_sort_by_table['table_name'] == table]\n",
    "    \n",
    "#######################\n",
    "# First time checking if the table is empty to distinduish date only contextref, second time checking to\n",
    "# determine if the member applies to the specific table.\n",
    "#######################\n",
    "            if 'Date_Only' in str(df_comp.loc[i,'reporting_period']):\n",
    "                member.append('Date_Only')\n",
    "            else:\n",
    "                fasb_sort_by_table = fasb_sort_by_table.loc[[x in s for x in fasb_sort_by_table['name']],:]\n",
    "                fasb_sort_by_table = fasb_sort_by_table.loc[fasb_sort_by_table['name'].str.contains('axis', case = False, na = False) == False,:]\n",
    "                fasb_sort_by_table['len_name'] = fasb_sort_by_table['name'].apply(lambda x: len(x))\n",
    "                if fasb_sort_by_table.empty:\n",
    "                    member.append('')\n",
    "\n",
    "                else:\n",
    "                    fasb_sort_by_table = fasb_sort_by_table.sort_values(by = ['depth','len_name'], ascending = [False, False])\n",
    "                    member.append(fasb_sort_by_table.reset_index().loc[0,'label'])\n",
    "\n",
    "        df_comp['member'] = member\n",
    "        df_comp['reporting_period'] = df_comp['reporting_period'].apply(lambda x: int(str(x).split('Date_Only')[0]) if 'Date_Only' in str(x) else x)\n",
    "        df_comp = df_comp[df_comp['member'] != '']\n",
    "        df_comp = df_comp[['CIK','Year','CutDate','reporting_period','table_name','decimals', \\\n",
    "                           'unitref', 'value','label','member','us-gaap','name','depth','contextref']]\n",
    "        df_comp.drop_duplicates(inplace = True)\n",
    "#######################\n",
    "# Wrangle Text Block\n",
    "#######################\n",
    "        text = []\n",
    "        for i in df_comp.loc[df_comp['label'].str.contains('Text Block', na = False, case = False),'value']:\n",
    "            soup = BeautifulSoup(i,\"lxml\")\n",
    "            pageText = soup.findAll(text=True)\n",
    "            text.append(' '.join(pageText))\n",
    "        df_comp.loc[df_comp['label'].str.contains('Text Block', na = False, case = False),'value'] = text\n",
    "    \n",
    "        df_all = pd.concat([df_all,df_comp.loc[df_comp['label'].str.contains('Text Block', na = False, case = False) == False,:]], ignore_index = True)\n",
    "    \n",
    "        df_all_text = pd.concat([df_all_text,df_comp.loc[df_comp['label'].str.contains('Text Block', na = False, case = False),:]], ignore_index = True)\n",
    "        count += 1\n",
    "        print(count)\n",
    "        #time.sleep(20)\n",
    "        if count%2 == 0:\n",
    "            df_all.to_sql('sp_500_tables',engine, if_exists = 'append')\n",
    "            df_all_text.to_sql('sp_500_tables_text',engine, if_exists = 'append')\n",
    "            del(df_all)\n",
    "            del(df_all_text)\n",
    "            df_all = pd.DataFrame(columns = ['CIK', 'Year', 'CutDate', 'reporting_period', 'table_name', 'decimals',\\\n",
    "                                             'unitref', 'value', 'label', 'member', 'us-gaap', 'name', 'depth','contextref'])\n",
    "            df_all_text = pd.DataFrame(columns = ['CIK', 'Year', 'CutDate', 'reporting_period', 'table_name', 'decimals',\\\n",
    "                                                  'unitref', 'value', 'label', 'member', 'us-gaap', 'name', 'depth','contextref'])\n",
    "            \n",
    "    except:\n",
    "        failed['CIK'].append(cik)\n",
    "        #time.sleep(20)\n",
    "#############\n",
    "# To prevent lefting out the last one\n",
    "#############\n",
    "df_all.to_sql('sp_500_tables',engine, if_exists = 'append')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
